                                                    ============================================
                                                          âœ¦ComparaciÃ³n General â€“ Ensayosâœ¦       
                                                    ============================================

âž¤Este repositorio contiene varios ensayos de redes neuronales convolucionales para clasificar el alfabeto ASL. 
âž¤Cada ensayo incluye su propio modelo, configuraciÃ³n y resultados, permitiendo comparar cÃ³mo cambian el rendimiento y la estabilidad al modificar arquitectura, activaciÃ³n, regularizaciÃ³n y optimizador.

ðŸŸ§Se muestra un resumen de los ensayos ordenados de mejor a peor rendimiento

--------------------------------------------------------------------------------------------------------------------------------------------------------------------

ðŸ’ Ensayo Preentrenado - EfficientNet-B0

-Transfer learning desde ImageNet.
-Solo se ajustan los Ãºltimos bloques y el clasificador.
-Mayor precisiÃ³n y mejor generalizaciÃ³n.

ðŸ’ Ensayo 1 - Arquitectura Optimizada

-CNN 16â†’32â†’64â†’128.
-BatchNorm, ReLU, Dropout y ReduceLROnPlateau.
-Modelo equilibrado y estable sin preentrenado.

ðŸ’ Ensayo 2 - CNN Ligera

-Arquitectura 16â†’32â†’32â†’64.
-Mish + Dropout2D + AdamW.
-RÃ¡pida, eficiente y con muy buen rendimiento para su tamaÃ±o.

ðŸ’ Ensayo 4 - CNN Profunda y Estrecha

-Filtros mÃ­nimos: 1â†’2â†’4â†’8â†’16.
-GELU + Adamax.
-Explora el lÃ­mite inferior de capacidad; mejora respecto al Ensayo 3.

ðŸ’ Ensayo 3 â€” CNN Simple 

-Solo 2 bloques convolucionales: 32â†’64.
-SiLU + RMSprop.
-Modelo base usado como referencia.
